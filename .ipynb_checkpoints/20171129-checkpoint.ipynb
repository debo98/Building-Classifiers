{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "# Assignment 1\n",
    "This jupyter notebook is meant to be used in conjunction with the full questions in the assignment pdf.\n",
    "\n",
    "## Instructions\n",
    "- Write your code and analyses in the indicated cells.\n",
    "- Ensure that this notebook runs without errors when the cells are run in sequence.\n",
    "- Do not attempt to change the contents of the other cells.\n",
    "\n",
    "## Submission\n",
    "- Ensure that this notebook runs without errors when the cells are run in sequence.\n",
    "- Rename the notebook to `<roll_number>.ipynb` and submit ONLY the notebook file on moodle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "### Environment setup\n",
    "\n",
    "The following code reads the train and test data (provided along with this template) and outputs the data and labels as numpy arrays. Use these variables in your code.\n",
    "\n",
    "---\n",
    "#### Note on conventions\n",
    "In mathematical notation, the convention is tha data matrices are column-indexed, which means that a input data $x$ has shape $[d, n]$, where $d$ is the number of dimensions and $n$ is the number of data points, respectively.\n",
    "\n",
    "Programming languages have a slightly different convention. Data matrices are of shape $[n, d]$. This has the benefit of being able to access the ith data point as a simple `data[i]`.\n",
    "\n",
    "What this means is that you need to be careful about your handling of matrix dimensions. For example, while the covariance matrix (of shape $[d,d]$) for input data $x$ is calculated as $(x-u)(x-u)^T$, while programming you would do $(x-u)^T(x-u)$ to get the correct output shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 784) (1000, 784)\n",
      "(6000,) (1000,)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def read_data(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    num_points = len(lines)\n",
    "    dim_points = 28 * 28\n",
    "    data = np.empty((num_points, dim_points))\n",
    "    labels = np.empty(num_points)\n",
    "    \n",
    "    for ind, line in enumerate(lines):\n",
    "        num = line.split(',')\n",
    "        labels[ind] = int(num[0])\n",
    "        data[ind] = [ int(x) for x in num[1:] ]\n",
    "        \n",
    "    return (data, labels)\n",
    "\n",
    "train_data, train_labels = read_data(\"sample_train.csv\")\n",
    "test_data, test_labels = read_data(\"sample_test.csv\")\n",
    "print(train_data.shape, test_data.shape)\n",
    "print(train_labels.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "# Questions\n",
    "---\n",
    "## 1.3.1 Representation\n",
    "The next code cells, when run, should plot the eigen value spectrum of the covariance matrices corresponding to the mentioned samples. Normalize the eigen value spectrum and only show the first 100 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fc081345160>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Samples corresponding to the last digit of your roll number (plot a)\n",
    "\n",
    "indices9 = np.where(train_labels == 9)\n",
    "data9 = train_data[indices9]\n",
    "\n",
    "cov9 = np.cov(data9)\n",
    "\n",
    "eigen_values9 = np.linalg.eigvals(cov9)\n",
    "eigen_values9 /= np.linalg.norm(eigen_values9)\n",
    "\n",
    "x = np.arange(100)\n",
    "plot_data9 = np.real(eigen_values9[0:100])\n",
    "plt.scatter(x, plot_data9)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fc0812e05c0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Samples corresponding to the last digit of (your roll number + 1) % 10 (plot b)\n",
    "\n",
    "indices0 = np.where(train_labels == 0)\n",
    "data0 = train_data[indices0]\n",
    "\n",
    "cov0 = np.cov(data0)\n",
    "\n",
    "eigen_values0 = np.linalg.eigvals(cov0)\n",
    "eigen_values0 /= np.linalg.norm(eigen_values0)\n",
    "\n",
    "x = np.arange(100)\n",
    "plot_data0 = np.real(eigen_values0[0:100])\n",
    "plt.scatter(x, plot_data0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All training data (plot c)\n",
    "\n",
    "data_full = train_data\n",
    "cov_full = np.cov(data_full)\n",
    "\n",
    "eigen_values_full = np.linalg.eigvals(cov_full)\n",
    "eigen_values_full /= np.linalg.norm(eigen_values_full)\n",
    "\n",
    "x = np.arange(100)\n",
    "plot_data_full = np.real(eigen_values_full[0:100])\n",
    "plt.scatter(x, plot_data_full)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly selected 50% of the training data (plot d)\n",
    "\n",
    "# Selecting random values \n",
    "indices50 = np.random.choice(int(train_data.shape[0]),int(train_data.shape[0]/2))\n",
    "data50 = train_data[indices50]\n",
    "cov50 = np.cov(data50)\n",
    "\n",
    "eigen_values50 = np.linalg.eigvals(cov50)\n",
    "eigen_values50 /= np.linalg.norm(eigen_values50)\n",
    "\n",
    "x = np.arange(100)\n",
    "plot_data50 = np.real(eigen_values50[0:100])\n",
    "plt.scatter(x, plot_data50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "### 1.3.1 Question 1\n",
    "- Are plots a and b different? Why?\n",
    "- Are plots b and c different? Why?\n",
    "- What are the approximate ranks of each plot?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Plots A and B are slightly different because their distributions are different and hence eigen values are different.\n",
    "\n",
    "Plots B and C differ because B has very few significant eigen values, but since C includes the samples for all classes, it has more number of significant eigen values, hence the plot is not as steep as Plot B. This is clearly visible in the plots. \n",
    "\n",
    "Approximate Ranks can be seen by observing where the eigen values start to become zero. In the first two plots, this appears to be near 450 and in the last two plots, around 600-650\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "### 1.3.1 Question 2\n",
    "- How many possible images could there be?\n",
    "- What percentage is accessible to us as MNIST data?\n",
    "- If we had acces to all the data, how would the eigen value spectrum of the covariance matrix look?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Each of the 784 features per sample can take values from 0 to 255 (256 values). Hence, total possible images can be (256)^(784)\n",
    "\n",
    "Percentage avaiable to us is 7000/(256)^(784)*100 as total data with 6000/(256)^(784)*100 as training data and 1000/(256)^(784)*100 as test data.\n",
    "\n",
    "If we had access to all the data, the covariance matrix will be a diagonal matrix with equal eigen values and the plot will be a straight line. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## 1.3.2 Linear Transformation\n",
    "---\n",
    "### 1.3.2 Question 1\n",
    "How does the eigen spectrum change if the original data was multiplied by an orthonormal matrix? Answer analytically and then also validate experimentally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiplying by an orthonormal matrix will only rotate the data, but not change the relative positions (or distances) of the plot points. Eigen values remain the same, and so will the plot. Eigen vectors can change.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimental validation here.\n",
    "# Multiply your data (train_data) with an orthonormal matrix and plot the\n",
    "# eigen value specturm of the new covariance matrix.\n",
    "\n",
    "# code goes here\n",
    "\n",
    "randmatrix = np.random.randn(train_data.shape[0], train_data.shape[0])\n",
    "Qdecomposition, _ = np.linalg.qr(randmatrix)\n",
    "\n",
    "ortho_train_data = np.dot(Qdecomposition, train_data)\n",
    "\n",
    "covar = np.cov(ortho_train_data)\n",
    "\n",
    "eigen_values = np.linalg.eigvals(covar)\n",
    "eigen_values /= np.linalg.norm(eigen_values)\n",
    "\n",
    "x = np.arange(100)\n",
    "plot_data = np.real(eigen_values[0:100])\n",
    "plt.scatter(x, plot_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "### 1.3.2 Question 2\n",
    "If  samples  were  multiplied  by  784 Ã— 784  matrix  of rank 1 or 2, (rank deficient matrices), how will the eigen spectrum look like?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When multiplied by a rank deficient matrix with rank R, the data will assume the rank of the rank deficient matrix (R) and the eigen spectrum will hence have only R non-zero eigen values. It will be a very steep exponential curve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "### 1.3.2 Question 3\n",
    "Project the original data into the first and second eigenvectors and plot in 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting code here\n",
    "\n",
    "covar = np.cov(train_data)\n",
    "\n",
    "_, eigen_vectors = np.linalg.eig(covar)\n",
    "\n",
    "data_new = np.dot(eigen_vectors[:,0:2].T, train_data)\n",
    "plt.scatter(data_new[1],data_new[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## 1.3.3 Probabilistic View\n",
    "---\n",
    "In this section you will classify the test set by fitting multivariate gaussians on the train set, with different choices for decision boundaries. On running, your code should print the accuracy on your test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print accuracy on the test set using MLE\n",
    "\n",
    "data_new = train_data.T\n",
    "covar = np.cov(data_new)\n",
    "eigen_values, eigen_vectors = np.linalg.eig(covar)\n",
    "\n",
    "indices = eigen_values.argsort()[ : :-1]\n",
    "indices = indices[ :30]\n",
    "\n",
    "eigen_vectors_new = eigen_vectors[:, indices]\n",
    "new_train = train_data.dot(eigen_vectors_new)\n",
    "new_test = test_data.dot(eigen_vectors_new)\n",
    "\n",
    "res = np.zeros((10, new_test.shape[0]))\n",
    "\n",
    "for i in range(10):\n",
    "    indices = np.where(train_labels == i)\n",
    "    mean = np.mean(new_train[indices], axis = 0)\n",
    "    covar = np.cov(new_train[indices].T)\n",
    "    x = np.dot((new_test - mean), np.linalg.inv(covar))\n",
    "    y = np.dot(x, (new_test - mean).T)\n",
    "    res[i] = np.log(np.linalg.det(covar))/2 + np.diagonal(y)/2\n",
    "\n",
    "mn = np.argmin(res,axis=0)\n",
    "tot = np.sum(np.where(test_labels == mn, 1, 0))\n",
    "print(tot / 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print accuracy on the test set using MAP\n",
    "# (assume a reasonable prior and mention it in the comments)\n",
    "\n",
    "data_new = train_data.T\n",
    "covar = np.cov(data_new)\n",
    "eigen_values, eigen_vectors = np.linalg.eig(covar)\n",
    "\n",
    "indices = eigen_values.argsort()[ : :-1]\n",
    "indices = indices[ :30]\n",
    "\n",
    "eigen_vectors_new = eigen_vectors[:, indices]\n",
    "new_train = train_data.dot(eigen_vectors_new)\n",
    "new_test = test_data.dot(eigen_vectors_new)\n",
    "\n",
    "p = [0.13, 0.14, 0.04, 0.03, 0.15, 0.13, 0.05, 0.06, 0.15, 0.12]\n",
    "\n",
    "res = np.zeros((10,new_test.shape[0]))\n",
    "\n",
    "for i in range(10):\n",
    "    indices = np.where(train_labels == i)\n",
    "    mean = np.mean(new_train[indices], axis = 0)\n",
    "    covar = np.cov(new_train[indices].T)\n",
    "    x = np.dot((new_test - mean), np.linalg.inv(covar))\n",
    "    y = np.dot(x, (new_test - mean).T)\n",
    "    res[i] = np.log(np.linalg.det(covar))/2 + np.diagonal(y)/2 - np.log(p[i])\n",
    "\n",
    "mn = np.argmin(res, axis=0)\n",
    "tot = np.sum(np.where(test_labels == mn, 1, 0))\n",
    "print(tot / 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print accuracy using Bayesian pairwise majority voting method\n",
    "\n",
    "data_new = train_data.T\n",
    "covar = np.cov(data_new)\n",
    "eigen_values, eigen_vectors = np.linalg.eig(covar)\n",
    "\n",
    "indices = eigen_values.argsort()[ : :-1]\n",
    "indices = indices[ :30]\n",
    "\n",
    "eigen_vectors_new = eigen_vectors[:, indices]\n",
    "new_train = train_data.dot(eigen_vectors_new)\n",
    "new_test = test_data.dot(eigen_vectors_new)\n",
    "\n",
    "covar = np.zeros((10, 30, 30))\n",
    "mean = np.zeros((10, 30))\n",
    "\n",
    "res = np.zeros((10,new_test.shape[0]))\n",
    "\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        \n",
    "        indices = np.where(train_labels == j)\n",
    "        mean[j] = np.mean(new_train[indices], axis = 0)\n",
    "        covar[j] = np.cov(new_train[indices].T)\n",
    "        \n",
    "        indices = np.where(train_labels == i)\n",
    "        mean[i] = np.mean(new_train[indices], axis = 0)\n",
    "        covar[i] = np.cov(new_train[indices].T)\n",
    "        \n",
    "        covar_total = (covar[j] + covar[i])/2\n",
    "        \n",
    "        x = np.dot((new_test - mean[j]), np.linalg.inv(covar_total))\n",
    "        y = np.dot(x, (new_test - mean[j]).T)\n",
    "        res1 = np.log(np.linalg.det(covar_total))/2 + np.diagonal(y)/2\n",
    "        \n",
    "        x = np.dot((new_test - mean[i]), np.linalg.inv(covar_total))\n",
    "        y = np.dot(x, (new_test - mean[i]).T)\n",
    "        res2 = np.log(np.linalg.det(covar_total))/2 + np.diagonal(y)/2\n",
    "        \n",
    "        res[j] += np.where((res1 - res2) > 0, 1, 0)\n",
    "        res[i] += np.where((res2 - res1) >= 0, 1, 0)\n",
    "        \n",
    "\n",
    "mn = np.argmin(res,axis = 0)\n",
    "tot = np.sum(np.where(test_labels == mn, 1, 0))\n",
    "print(tot / 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print accuracy using Simple Perpendicular Bisector majority voting method\n",
    "\n",
    "data_new = train_data.T\n",
    "covar = np.cov(data_new)\n",
    "eigen_values, eigen_vectors = np.linalg.eig(covar)\n",
    "\n",
    "indices = eigen_values.argsort()[ : :-1]\n",
    "indices = indices[ :30]\n",
    "\n",
    "eigen_vectors_new = eigen_vectors[:, indices]\n",
    "new_train = train_data.dot(eigen_vectors_new)\n",
    "new_test = test_data.dot(eigen_vectors_new)\n",
    "\n",
    "covar = np.zeros((10, 30, 30))\n",
    "mean = np.zeros((10, 30))\n",
    "\n",
    "res = np.zeros((10,new_test.shape[0]))\n",
    "\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        \n",
    "        indices = np.where(train_labels == j)\n",
    "        mean[j] = np.mean(new_train[indices], axis = 0)\n",
    "        covar[j] = np.cov(new_train[indices].T)\n",
    "        \n",
    "        indices = np.where(train_labels == i)\n",
    "        mean[i] = np.mean(new_train[indices], axis = 0)\n",
    "        covar[i] = np.cov(new_train[indices].T)\n",
    "        \n",
    "        covar_total = (covar[j] + covar[i]) / 2\n",
    "        \n",
    "        y = np.dot((new_test - mean[j]), (new_test - mean[j]).T)\n",
    "        res1 = np.diagonal(y)/2\n",
    "        \n",
    "        y = np.dot((new_test - mean[i]), (new_test - mean[i]).T)\n",
    "        res2 = np.diagonal(y)/2\n",
    "        \n",
    "        res[j] += np.where((res1 - res2) > 0, 1, 0)\n",
    "        res[i] += np.where((res2 - res1) >= 0, 1, 0)\n",
    "        \n",
    "\n",
    "mn = np.argmin(res,axis = 0)\n",
    "tot = np.sum(np.where(test_labels == mn, 1, 0))\n",
    "print(tot / 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "### 1.3.3 Question 4\n",
    "Compare performances and salient observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy with different classifiers:\n",
    "\n",
    "+ MLE : 94.8 - MLE gives the highest accuracy. This is because we take the covariance matrix into complete account and the Mahalnobis distance to find the distance from the classifying hyperplane. \n",
    "+ MAP : 94.6 - MAP shows lower accuracy because we assume the test data is Gaussian with data distributed on the normal random variable class index. Since the data is actually not of that distribution, and we have approximated, we get lower accuracy.\n",
    "+ Bayesian Voting : 88.4 - Bayesian Voting equates the covariance matrix leading to loss of information thus performing poorer.\n",
    "+ Perpendicular Bisector : 75.3 - Since the covariance matrices are not equal, L2 norm is a really bad measure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## 1.3.4 Nearest Neighbour based Tasks and Design\n",
    "---\n",
    "### 1.3.4 Question 1 : NN Classification with various K\n",
    "Implement a KNN classifier and print accuracies on the test set with K=1,3,7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Print accuracies with K = 1, 3, 7\n",
    "\n",
    "dist = np.zeros(shape=(1000,6000))\n",
    "for i in range(len(test_data)):\n",
    "    for j in range(len(train_data)):\n",
    "        dist[i][j] = np.linalg.norm(train_data[j]-test_data[i])\n",
    "\n",
    "for k in [1,3,7]:\n",
    "    predictions = 0\n",
    "    for indices in range(1000):\n",
    "        count_majority_array = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "        test_sample_dist = np.argsort(dist[indices])[:k]\n",
    "        for k_test_dist in test_sample_dist:\n",
    "            calculated_label = int(train_labels[k_test_dist])\n",
    "            count_majority_array[calculated_label] += 1 \n",
    "        majority_label = np.argsort(count_majority_array)[ : :-1][0]\n",
    "        if majority_label == int(test_labels[indices]):\n",
    "            predictions += 1\n",
    "    accuracy = predictions/10\n",
    "    print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "### 1.3.4 Question 1 continued\n",
    "- Why / why not are the accuracies the same?\n",
    "- How do we identify the best K? Suggest a computational procedure with a logical explanation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracies differ on changing the value of K. \n",
    "\n",
    "When K is 1, we are only looking at the nearest neighbour.\n",
    "As K increases (to 3), we are considering 3 nearest neighbours, which gives us a chance to choose the majority of the K labels that we obtain.\n",
    "When K becomes large, we may be including far away points which will influence our decision making negatively. Hence accuracies change on basis of K. Typically, they first increase with increaisng K, and then decrease.\n",
    "\n",
    "K increases, peaks at maximum accuracy and then decreases. We can adopt a regression approach, start from a random point and keep climbing towards the peak, so find the K with highest accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "### 1.3.4 Question 2 :  Reverse NN based outlier detection\n",
    "A sample can be thought of as an outlier is it is NOT in the nearest neighbour set of anybody else. Expand this idea into an algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "# This cell reads mixed data containing both MNIST digits and English characters.\n",
    "# The labels for this mixed data are random and are hence ignored.\n",
    "mixed_data, _ = read_data(\"outliers.csv\")\n",
    "print(mixed_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "### 1.3.4 Question 3 : NN for regression\n",
    "Assume that each classID in the train set corresponds to a neatness score as:\n",
    "$$ neatness = \\frac{classID}{10} $$\n",
    "\n",
    "---\n",
    "Assume we had to predict the neatness score for each test sample using NN based techiniques on the train set. Describe the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the K nearest neighbours for a given test sample. Since these are real values between 0 and 1, and not discrete values unlike ClassIds, we cannot count the majority. \n",
    "Instead, Take a mean of these values, and then calculate the accuracy in terms of mean absolute error of the predicted value with the actual value (take the absolute difference between the two for every sample, add them and divide by number of samples in test data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "### 1.3.4 Question 3 continued\n",
    "Validate your algorithm on the test set. This code should print mean absolute error on the test set, using the train set for NN based regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "dist_neat = np.zeros(shape=(1000,6000))\n",
    "for i in range(len(test_data)):\n",
    "    for j in range(len(train_data)):\n",
    "        dist_neat[i][j]=np.linalg.norm(train_data[j]-test_data[i])\n",
    "        \n",
    "k = 5\n",
    "abs_error = 0\n",
    "for indices in range(1000):\n",
    "    sum_values = 0\n",
    "    test_sample_dist = np.argsort(dist_neat[indices])[ :k]\n",
    "    for index in test_sample_dist:\n",
    "        sum_values += train_labels[index]/10\n",
    "    predicted_value = sum_values/k \n",
    "    abs_error += abs(predicted_value - test_labels[indices]/10)\n",
    "print(abs_error/1000) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "---\n",
    "# FOLLOW THE SUBMISSION INSTRUCTIONS\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
